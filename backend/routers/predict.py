from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session
import joblib
import pandas as pd
import json
import os
import sys

# --- IMPORT CRUCIAL POUR LE MOD√àLE SMOTE ---
# M√™me si on ne l'utilise pas directement dans le code, 
# joblib en a besoin pour charger le pipeline.
import imblearn 
# -------------------------------------------

# Nos modules
from core.database import get_db
from core.security import verify_token
from models.users import User
from models.history import PredictionHistory
from schemas.schemas import EmployeeData, PredictionResponse

router = APIRouter(tags=["Machine Learning"])

# ==============================================================================
# 1. Chargement Robuste du Mod√®le
# ==============================================================================

# On calcule le chemin absolu vers backend/model.pkl
# __file__ = routers/predict.py -> parent = routers -> grand-parent = backend
current_dir = os.path.dirname(os.path.abspath(__file__))
backend_dir = os.path.dirname(current_dir)
model_path = os.path.join(backend_dir, "model.pkl")

print(f"üìÇ Recherche du mod√®le ici : {model_path}")

try:
    if os.path.exists(model_path):
        model = joblib.load(model_path)
        print(f"‚úÖ VRAI Mod√®le ML charg√© avec succ√®s ! (Type: {type(model).__name__})")
    else:
        print("‚ùå Fichier model.pkl introuvable au chemin indiqu√©.")
        model = None
except ImportError as e:
    print(f"‚ùå ERREUR CRITIQUE : Il manque une librairie pour lire le mod√®le.")
    print(f"D√©tail : {e}")
    print("üí° Solution : pip install imbalanced-learn scikit-learn==1.3.2")
    model = None
except Exception as e:
    print(f"‚ùå Erreur inconnue au chargement : {e}")
    model = None


# ==============================================================================
# 2. La Route de Pr√©diction
# ==============================================================================

@router.post("/predict", response_model=PredictionResponse)
def predict_churn(
    data: EmployeeData, 
    payload: dict = Depends(verify_token), # S√©curit√© JWT
    db: Session = Depends(get_db)
):
    # V√©rification initiale
    if model is None:
        raise HTTPException(
            status_code=500, 
            detail="Le mod√®le ML n'est pas charg√© sur le serveur. V√©rifiez les logs."
        )

    # R√©cup√©ration de l'utilisateur
    username = payload.get("sub")
    current_user = db.query(User).filter(User.username == username).first()
    if not current_user:
        raise HTTPException(status_code=401, detail="Utilisateur introuvable")

    try:
        # 3. Pr√©paration des donn√©es (JSON -> DataFrame)
        # On utilise model_dump() pour Pydantic v2 (ou dict() pour v1)
        input_data = data.model_dump()
        input_df = pd.DataFrame([input_data]) 

        # 4. Pr√©diction
        # Le pipeline va g√©rer tout seul le Scaling et le OneHotEncoder !
        # .predict_proba renvoie [[Prob_No, Prob_Yes]] -> on prend [0][1]
        probability = model.predict_proba(input_df)[0][1]

        # 5. Sauvegarde en Base de Donn√©es
        history_entry = PredictionHistory(
            user_id=current_user.id,
            probability=probability,
            # On stocke les donn√©es d'entr√©e en JSON pour tra√ßabilit√©
            input_data=json.dumps(input_data, default=str) 
        )
        db.add(history_entry)
        db.commit()

        # 6. R√©ponse
        return {
            "churn_probability": round(probability, 2),
            "alert": probability > 0.50
        }

    except Exception as e:
        # En cas d'erreur (ex: colonne manquante, format incorrect)
        print(f"Erreur pr√©diction: {e}")
        raise HTTPException(status_code=400, detail=f"Erreur lors de la pr√©diction : {str(e)}")